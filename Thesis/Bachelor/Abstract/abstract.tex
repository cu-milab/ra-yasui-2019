\documentclass{jsarticle}
\usepackage{abst, epsf,graphicx, tabularx, ascmac}
%\usepackage{comment}

\newcommand{\bd}[1]{\mbox{\boldmath$#1$}}
\newcommand{\mysubsec}[1]{\noindent {\bf #1} \ \ }
\newcommand{\down}[1]{\raisebox{-0.0mm}{{\scriptsize #1}}}

\makeatletter
\newcommand{\figcaption}[1]{\def\@captype{figure}\caption{#1}}
\newcommand{\tblcaption}[1]{\def\@captype{table}\caption{#1}}
\makeatother


\title{機械学習を用いた変形ARマーカの位置姿勢推定}
\prof{山内 悠嗣}
\name{ER17076 安井理}

\begin{document}
\maketitle

%-------------------------------------------------------------------------
\sec{はじめに}
ARマーカに代表される2次元コードは，製造での工程管理やロボット認識機能の広い分野で利用されている．2次元コードの画像上の見え方から3次元位置・姿勢を推定できるが，2次元コードに変形が生じた場合には著しく認識性能が低下する．既に機械学習により2次元コードを検出する方法[1]が提案されているが，3次元姿勢の推定までは至っていない．

そこで，本研究では機械学習を用いた変形ARマーカの位置姿勢推定法を提案する．
変形したAR マーカをSSD(Single ShotMultiBox Detector)[2]
より検出し，Augument Autoencoder(AAE)[3]により3次元姿勢を推定する．


\sec{提案手法の概要}
本研究は，SSDによる変形ARマーカの検出とAAEによる3次元姿勢推定の2つの処理に分けられる．

SSDにより，撮影したRGB画像内のARマーカのID，座標位置を検出する．

AAEでは，SSDの検出時に得られたBounding box情報を元に作成したARマーカ画像を入力し，
平面状ARマーカへの復元と姿勢推定を行う．

\begin{figure}[ht]
\vspace{0zh}
\setlength{\epsfxsize}{6.5cm}
\centerline{\epsfbox{./eps/nagare.eps}}
\vspace{-1zh}
\caption{提案手法の流れ}
\label{flow}
\vspace{-2zh}
\end{figure}

%---------------------------------------------------------------------------------------
\subsec{Augumented Autoencoder}
後述のAAEについて説明していく．変化が与えられた画像から変化を取り除いた画像として生成するように学習するオートエンコーダーである．
AAEの学習の流れを図\ref{BB}に示す．平面状のARマーカが貼られた教師データ図2（a）に変化を与えた図2（b）をAAEに入力し，図2(c)を出力する．この時，図2(c)の次元$x'_i$と図2(a)の次元$x_i$の損失関数$l$を平均二乗誤差式（1）で求め，誤差が少なくなるように学習を行う．
学習を行うことで，AAEに変形ARマーカを入力したときに，平面状のARマーカを出力可能にする．

\begin{eqnarray}
\label{sonsitu}
l_2=\sum_{i} ||x'_i-x_i||_2
\end{eqnarray}

\begin{figure}[ht]
\vspace{0zh}
\setlength{\epsfxsize}{7.5cm}
\centerline{\epsfbox{./eps/学習の流れ.eps}}
\vspace{0zh}
\caption{AAEの学習の流れ}
\label{BB}
\vspace{1zh}
\end{figure}




%---------------------------------------------------------------------------------
\subsec{AAEによる姿勢推定}
次に，学習済みのAAEを用いて姿勢推定を行う．
姿勢推定は，AAEのエンコーダーから出力される画像の潜在変数$z$を使用して行う．
ARマーカの姿勢をrollを0$\sim$360度, pitchを-35$\sim$35度, yawを-15$\sim15$度に範囲を設定し，各角度１度刻みで回転させた姿勢情報を持つ792,360枚の画像を用意し，エンコーダーに入力する．出力された潜在変数$z_n$をデータベースとして保存する．

姿勢推定時にはSSDにより得られた画像をエンコーダーに入力し，出力される潜在変数$z_{test}$とデータベースに保存した潜在変数$z_n$のコサイン類似度を式(2)により計算する．そして，最も近い潜在変数の姿勢情報を物体姿勢として決定する．



%姿勢データベースは各姿勢のARマーカ画像をAAEに入力し，獲得した潜在変数$z_n$を蓄積することで作成する．
%本研究ではARマーカの姿勢をrollを0$\sim$360度, pitchを-35$\sim$35度, yawを-15$\sim15$度の範囲に設定した．
%変形ARマーカの潜在変数$z_{test}$と姿勢データベースの潜在変数との
%コサイン類似度を式(2)により計算する．そして，最も近い潜在変数の姿勢情報を物体姿勢として決定する．
%\footnotesize{
\begin{eqnarray}
\label{cos}
cos_n=\frac{z_n z_{test}}{||z_n|| ||z_{test}||}
%=\frac{x_1x'_1+\cdots+x_n x'_n}{\sqrt{x^2_1+\cdots+x'^2_n}\sqrt{x^2_1+\cdots+x'^2_n}}
\end{eqnarray}


%\begin{figure}[ht]
%\vspace{0zh}
%\setlength{\epsfxsize}{7.5cm}
%\centerline{\epsfbox{./eps/姿勢推定.eps}}
%\vspace{0zh}
%\caption{姿勢推定の流れ}
%\label{GG}
%\vspace{-1.0zh}
%\end{figure}

%------------------------------------------------------------------------------


\sec{評価実験}


提案手法の有効性を確認するために評価実験を行う．
評価方法としてgazeboのシミュレーション空間上にARマーカを円柱に張り付けたモデルを表示し，撮影を行う．
ARマーカのモデルは，半径20,30,40[mm]の円柱を各モデル姿勢100枚ずつ用意する．
撮影されたモデル画像をSSDによって検出し，その際に得られたバウンディングボックスの画像を128$\times$128にリサイズし，使用する．
バウンディングボックスの画像を入力として提案手法により姿勢推定を行う．評価用画像のモデル姿勢と提案手法により推定された姿勢の[roll,pitch,yaw]を比較し平均絶対誤差（MAE）により評価する．

評価結果を表\ref{hyouka}に示す．各半径どれも4前後の誤差が生じるという結果となった．
%３画像の復元は正確に行えていることから，データベースからの決定時に誤差が乗じていると考えられる．

%と平均絶対誤差（MAE）



\begin{table}[h]
        \vspace{0zh}
          \begin{center}
            \caption{提案手法における姿勢推定の精度}
            \label{hyouka}
            \begin{tabular}{c|c|c|c|c} \hline
              円柱半径[mm]   &平均誤差& roll& pitch & yaw \\ \hline
              20&4.79& 4.14 & 6.12 & 4.11 \\ \hline
              30& 3.97&3.94 & 4.80 & 3.16 \\ \hline
              40&4.72 &4.47 &5.32  &4.39 \\ \hline
              \end{tabular}
          \end{center}
        \vspace{-1.0zh}
\end{table}

%\begin{table}[h]
        %\vspace{-1.8zh}
         % \begin{center}
       %     \caption{MAE}
       %     \label{hyouka2}
     %       \begin{tabular}{l|c|c|c} \hline
   %           円柱半径[mm]   & roll& pitch & yaw \\ \hline
 %20  & 2.43° & 2.2° & 2.5° \\ \hline
         %     30  & 0° & 1° & 2.2° \\ \hline
       %       40  & 1° & 1° & 1° \\ \hline
     %         50  & 0°& 2° & 1° \\ \hline
   %           \end{tabular}
 %         \end{center}
 %       \vspace{-1.0zh}
%\end{table}





\sec{おわりに}
本研究では，変形ARマーカの認識及び姿勢推定を提案し，機械学習によってARマーカの座標位置，姿勢を推定できる事を確認した．今後は，提案手法のよる実世界での姿勢推定を研究を行う予定である．

\markboth{参考文献}{}     %% BibTeX を使う
%\bibliographystyle{jalpha}
%\newcommand{\noop}[1]{}
%\bibliographystyle{jabbrv}
%\bibliography{ref}

\begin{thebibliography}{1}
%{\scriptsize 
%\bibitem{hog+motion}
%Wei Liu，Dragomir Anguelov， Dumitru Erhan，Christian Szegedy，Scott Reed，Cheng-Yang Fu， Alexander C. Berg : ``SSD: Single Shot MultiBox Detector'', Proc. of ECCV, 2016.}

{\scriptsize
\bibitem{fasterrcnn}
https://github.com/cu-milab/ra-suzuki-2018/blob/master/Thesis/Bachelor/4th/GraduationThesis/Thesis.pdf}


{\scriptsize
\bibitem{hog+motion}
W．Liu　{\em et al. }: "SSD: Single Shot MultiBox Detector", ECCV,2016.}

{\scriptsize 
\bibitem{pixel}
Martin Sundermeyer {\em et al．}: ``Implicit 3D Orientation Learning for 6D Object Detection from RGB Images'', ECCV， 2016．}

\end{thebibliography}
\end{document}